{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "#from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading training files, removing NaN's and dropping duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Brillantaisia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>genus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>plant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Acanthaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DATE</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LETTERS</td>\n",
       "      <td>IUCN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>List</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Threatened</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Species</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Circa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Survive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>draw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>influences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>hardcore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>experimental</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>emo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>progressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9917872</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Affeln</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9917874</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Altenaffeln</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9917876</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Blintrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9917883</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>advowson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9917901</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>conventuals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9917938</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Kamptz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9917942</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Theilnahme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9917944</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>adlichen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9917945</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Klosterstellen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9917973</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Herzogtumer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9918042</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Constructivists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9918045</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Rodchenko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9918064</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Mathilde's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9918073</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Geiselhoring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9918080</th>\n",
       "      <td>DATE</td>\n",
       "      <td>12 December 1859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9918095</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Neufchatel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9918160</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Belik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9918167</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Schmucker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9918172</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Neuhorst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9918217</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Neuillé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9918259</th>\n",
       "      <td>DATE</td>\n",
       "      <td>October 1865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9918267</th>\n",
       "      <td>DATE</td>\n",
       "      <td>14 January 1867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9918278</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Neukirch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9918313</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Eliswil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9918316</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Christerode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9918360</th>\n",
       "      <td>LETTERS</td>\n",
       "      <td>vun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9918361</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Neileininge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9918364</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Neulliac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9918368</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Neulieg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9918426</th>\n",
       "      <td>PLAIN</td>\n",
       "      <td>perceptible</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>484145 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           class            before\n",
       "0          PLAIN     Brillantaisia\n",
       "1          PLAIN                is\n",
       "2          PLAIN                 a\n",
       "3          PLAIN             genus\n",
       "4          PLAIN                of\n",
       "5          PLAIN             plant\n",
       "6          PLAIN                in\n",
       "7          PLAIN            family\n",
       "8          PLAIN       Acanthaceae\n",
       "9          PUNCT                 .\n",
       "10          DATE              2006\n",
       "11       LETTERS              IUCN\n",
       "12         PLAIN               Red\n",
       "13         PLAIN              List\n",
       "15         PLAIN        Threatened\n",
       "16         PLAIN           Species\n",
       "18         PLAIN             Circa\n",
       "19         PLAIN           Survive\n",
       "20         PLAIN              draw\n",
       "21         PLAIN        influences\n",
       "22         PLAIN              from\n",
       "23         PLAIN              soft\n",
       "24         PLAIN              rock\n",
       "25         PUNCT                 ,\n",
       "26         PLAIN              post\n",
       "27         PLAIN          hardcore\n",
       "29         PLAIN      experimental\n",
       "32         PLAIN               emo\n",
       "34         PLAIN       progressive\n",
       "37         PLAIN               art\n",
       "...          ...               ...\n",
       "9917872    PLAIN            Affeln\n",
       "9917874    PLAIN       Altenaffeln\n",
       "9917876    PLAIN          Blintrop\n",
       "9917883    PLAIN          advowson\n",
       "9917901    PLAIN       conventuals\n",
       "9917938    PLAIN            Kamptz\n",
       "9917942    PLAIN        Theilnahme\n",
       "9917944    PLAIN          adlichen\n",
       "9917945    PLAIN    Klosterstellen\n",
       "9917973    PLAIN       Herzogtumer\n",
       "9918042    PLAIN   Constructivists\n",
       "9918045    PLAIN         Rodchenko\n",
       "9918064    PLAIN        Mathilde's\n",
       "9918073    PLAIN      Geiselhoring\n",
       "9918080     DATE  12 December 1859\n",
       "9918095    PLAIN        Neufchatel\n",
       "9918160    PLAIN             Belik\n",
       "9918167    PLAIN         Schmucker\n",
       "9918172    PLAIN          Neuhorst\n",
       "9918217    PLAIN           Neuillé\n",
       "9918259     DATE      October 1865\n",
       "9918267     DATE   14 January 1867\n",
       "9918278    PLAIN          Neukirch\n",
       "9918313    PLAIN           Eliswil\n",
       "9918316    PLAIN       Christerode\n",
       "9918360  LETTERS               vun\n",
       "9918361    PLAIN       Neileininge\n",
       "9918364    PLAIN          Neulliac\n",
       "9918368    PLAIN           Neulieg\n",
       "9918426    PLAIN       perceptible\n",
       "\n",
       "[484145 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PATH=\"C:\\\\Users\\\\Dani-Desktop\\\\Desktop\\\\NLP DATA\\\\en_train.csv\"\n",
    "df= pd.read_csv(PATH)\n",
    "exclude_classes_car = ['ELECTRONIC']\n",
    "df_c = df.loc[df['class'].isin(exclude_classes_car) == False]\n",
    "df_x= df_c.iloc[:-1,2:4]\n",
    "df_x = df_x.drop_duplicates()\n",
    "df_x=df_x.dropna()\n",
    "df_x=df_x.drop(2680666) # dropping the max sized word here, ALWAYS DO THIS\n",
    "df_x=df_x.drop(2595490)\n",
    "df_x=df_x.drop(2972460)\n",
    "display(df_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PLAIN' 'PUNCT' 'DATE' 'LETTERS' 'CARDINAL' 'VERBATIM' 'DECIMAL' 'MEASURE'\n",
      " 'MONEY' 'ORDINAL' 'TIME' 'DIGIT' 'FRACTION' 'TELEPHONE' 'ADDRESS']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Brillantaisia'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique_classes=df_x[\"class\"].unique()\n",
    "lenx=len(unique_classes)\n",
    "\n",
    "print (unique_classes)\n",
    "\n",
    "##GETTING ALL THE WORD IN THE VOCAB\n",
    "words=df_x.iloc[:,1]\n",
    "\n",
    "display(words[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot-Vec for all our Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HotVec for our CLasses\n",
    "class_hot_vec= np.zeros((lenx,lenx),int) \n",
    "np.fill_diagonal(class_hot_vec,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Number of Words after removing NaN's and dropping duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484145\n"
     ]
    }
   ],
   "source": [
    "print (len(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(s, el):\n",
    "    for i in s.index:\n",
    "        if s[i] == el: \n",
    "            return i\n",
    "    return None\n",
    "#words=words.drop(2680666)  #words=words.drop(2680666)\n",
    "#print (find(words, \"groupsAdenosinergicAdrenergicCannabinoidergicCholinergicDopaminergicGABAergicGlycinergicHistaminergicMelatonergicMonoaminergicOpioidergic\"))\n",
    "#print (find(words, \"TomotsuneAritsuneTsuneyasuYasutomoYasukageTomoyasuMunetomoYasumuneNoriyasuTomoyasuYasukageYasuyoshi\"))\n",
    "#print (find(words, \"PasséSouvenirRomanceLiedAgitatoAdieuReverieCapriceInquiétudeIntermezzoOp\"))\n",
    "#print (find(words, \"BalianBalogoBalungisanBinangonanBulacanBulawanCalapeDalamaFatima\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max word :  LevushkovskyPlastunovskyDyadkovskyBryukhovetskyVedmedovskyPlatmyrovskyPashkovskyKushchevskyKyslyakovskyIvanovskyKonelovskySerhiyevskyDonskyKrylovskyKanivskyBaturynskyPopovychevskyVasyurynskyNezamaikovskyIrkliyevskyShcherbynovskyTytarovskyShkurynskyKurenevskyRohovskyKorsunksyKalnybolotskyHumanskyDerevyantsovskyStebliyivsky\n",
      "max word len:  323\n"
     ]
    }
   ],
   "source": [
    "#words=words.drop(2680666) # dropping the max sized word here, ALWAYS DO THIS\n",
    "#words=words.drop(2595490)\n",
    "#words=words.drop(2972460)\n",
    "#words=words.drop(888311)\n",
    "max_word=[str(i) for i in words]\n",
    "max_word=sorted(max_word,key=len)\n",
    "x=-1\n",
    "max_word_len=len(max_word[x])\n",
    "#len(sorted_word_list[9913279-3])max_word_len\n",
    "print (\"max word : \", max_word[x])\n",
    "print (\"max word len: \", max_word_len)\n",
    "\n",
    "\n",
    "#Following is the Max word:\n",
    "#groupsAdenosinergicAdrenergicCannabinoidergicCholinergicDopaminergicGABAergicGlycinergicHistaminergicMelatonergicMonoaminergicOpioidergic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting all the unique characters in our list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484145\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Շ',\n",
       " '追',\n",
       " '尾',\n",
       " 'ـ',\n",
       " 'あ',\n",
       " '修',\n",
       " '附',\n",
       " '滸',\n",
       " 'ค',\n",
       " '遠',\n",
       " '람',\n",
       " 'জ',\n",
       " '4',\n",
       " '銀',\n",
       " 'y',\n",
       " 'ữ',\n",
       " '約',\n",
       " 'ц',\n",
       " '装',\n",
       " '나',\n",
       " '頓',\n",
       " '會',\n",
       " '向',\n",
       " '线',\n",
       " 'ぜ',\n",
       " '等',\n",
       " '闘',\n",
       " '葉',\n",
       " 'З',\n",
       " '径',\n",
       " '奴',\n",
       " '陀',\n",
       " '露',\n",
       " 'ᛁ',\n",
       " 'カ',\n",
       " '视',\n",
       " '岳',\n",
       " 'ま',\n",
       " '島',\n",
       " 'в',\n",
       " '販',\n",
       " '앨',\n",
       " '浙',\n",
       " '人',\n",
       " '鋘',\n",
       " '需',\n",
       " '约',\n",
       " '尋',\n",
       " '知',\n",
       " '乍',\n",
       " '紫',\n",
       " 'な',\n",
       " '飛',\n",
       " 'ず',\n",
       " '巣',\n",
       " '계',\n",
       " '榊',\n",
       " '始',\n",
       " '奔',\n",
       " 'Ε',\n",
       " '努',\n",
       " '韓',\n",
       " 'Д',\n",
       " '桂',\n",
       " '遇',\n",
       " '구',\n",
       " '死',\n",
       " '勇',\n",
       " 'И',\n",
       " '柳',\n",
       " '돌',\n",
       " '屑',\n",
       " 'ᛏ',\n",
       " '외',\n",
       " '佐',\n",
       " '影',\n",
       " '雪',\n",
       " 'Ц',\n",
       " '撲',\n",
       " 'ሕ',\n",
       " '典',\n",
       " 'е',\n",
       " 'Ṭ',\n",
       " '图',\n",
       " '罰',\n",
       " '葵',\n",
       " '창',\n",
       " '覧',\n",
       " '衢',\n",
       " '団',\n",
       " '蘭',\n",
       " 'ማ',\n",
       " '笠',\n",
       " '崔',\n",
       " 'ھ',\n",
       " '즐',\n",
       " 'Ē',\n",
       " '큐',\n",
       " 'ተ',\n",
       " '遮',\n",
       " '漢',\n",
       " '郡',\n",
       " '的',\n",
       " '厂',\n",
       " 'ở',\n",
       " '手',\n",
       " 'ள',\n",
       " '桃',\n",
       " '坂',\n",
       " '星',\n",
       " 'ぢ',\n",
       " 'ϵ',\n",
       " '槼',\n",
       " '绚',\n",
       " 'ж',\n",
       " '등',\n",
       " '阮',\n",
       " '璩',\n",
       " 'Ð',\n",
       " '暎',\n",
       " '예',\n",
       " '媒',\n",
       " 'R',\n",
       " '張',\n",
       " '어',\n",
       " 'D',\n",
       " '登',\n",
       " '巧',\n",
       " '方',\n",
       " '威',\n",
       " '酒',\n",
       " 'א',\n",
       " '辉',\n",
       " 'მ',\n",
       " '动',\n",
       " 'Ψ',\n",
       " '摦',\n",
       " '식',\n",
       " '려',\n",
       " '¥',\n",
       " '세',\n",
       " '道',\n",
       " '構',\n",
       " 'ץ',\n",
       " '浩',\n",
       " 'Χ',\n",
       " 'ラ',\n",
       " 'ม',\n",
       " '授',\n",
       " '瑶',\n",
       " 'ˀ',\n",
       " '凤',\n",
       " '突',\n",
       " '榕',\n",
       " '奚',\n",
       " '«',\n",
       " '宿',\n",
       " '室',\n",
       " '⅓',\n",
       " '申',\n",
       " '감',\n",
       " 'ハ',\n",
       " 'ョ',\n",
       " '橘',\n",
       " '期',\n",
       " 'ન',\n",
       " '다',\n",
       " '導',\n",
       " '矿',\n",
       " '훈',\n",
       " 'ὼ',\n",
       " '랙',\n",
       " '및',\n",
       " 'ẩ',\n",
       " '票',\n",
       " '틀',\n",
       " 'ぱ',\n",
       " '陈',\n",
       " '辛',\n",
       " 'ј',\n",
       " 'ẳ',\n",
       " '皆',\n",
       " '홀',\n",
       " '監',\n",
       " '変',\n",
       " '長',\n",
       " 'l',\n",
       " 'б',\n",
       " '晴',\n",
       " '珠',\n",
       " 't',\n",
       " 'ڈ',\n",
       " 'J',\n",
       " '嬸',\n",
       " 'に',\n",
       " '郧',\n",
       " '开',\n",
       " '真',\n",
       " '阿',\n",
       " '結',\n",
       " '蛋',\n",
       " '港',\n",
       " '圖',\n",
       " 'ぶ',\n",
       " 'ρ',\n",
       " 'ぐ',\n",
       " 'ἴ',\n",
       " '답',\n",
       " '君',\n",
       " '胖',\n",
       " '步',\n",
       " 'の',\n",
       " '悪',\n",
       " '渝',\n",
       " '画',\n",
       " '머',\n",
       " '宣',\n",
       " '備',\n",
       " 'к',\n",
       " 'ὠ',\n",
       " '夫',\n",
       " '叙',\n",
       " 'ｒ',\n",
       " '侍',\n",
       " '釋',\n",
       " '町',\n",
       " 'ر',\n",
       " '찬',\n",
       " '维',\n",
       " '思',\n",
       " 'ʊ',\n",
       " '伎',\n",
       " '霽',\n",
       " '엑',\n",
       " '楊',\n",
       " '玲',\n",
       " '戰',\n",
       " 'j',\n",
       " '嶋',\n",
       " 'º',\n",
       " '機',\n",
       " 'Υ',\n",
       " '峴',\n",
       " '現',\n",
       " '彰',\n",
       " '鈴',\n",
       " '野',\n",
       " '击',\n",
       " '詔',\n",
       " '齊',\n",
       " '鬼',\n",
       " '여',\n",
       " 'ქ',\n",
       " '蟲',\n",
       " 'Н',\n",
       " '落',\n",
       " '偵',\n",
       " '詩',\n",
       " 'շ',\n",
       " '負',\n",
       " '培',\n",
       " '抗',\n",
       " '컵',\n",
       " 'ェ',\n",
       " '型',\n",
       " '警',\n",
       " 'स',\n",
       " '赫',\n",
       " '愈',\n",
       " '实',\n",
       " 'Э',\n",
       " '琴',\n",
       " 'Q',\n",
       " '伸',\n",
       " '稲',\n",
       " 'ゼ',\n",
       " '爺',\n",
       " '陸',\n",
       " '歌',\n",
       " '2',\n",
       " '二',\n",
       " '必',\n",
       " '建',\n",
       " 'ῴ',\n",
       " '熊',\n",
       " '戒',\n",
       " '打',\n",
       " '하',\n",
       " '科',\n",
       " '즈',\n",
       " '斎',\n",
       " '義',\n",
       " '勝',\n",
       " '流',\n",
       " 'Θ',\n",
       " 'Ձ',\n",
       " 'щ',\n",
       " 'એ',\n",
       " '객',\n",
       " '밥',\n",
       " '함',\n",
       " '潮',\n",
       " 'Ι',\n",
       " '봐',\n",
       " '惧',\n",
       " '对',\n",
       " 'ᚨ',\n",
       " '东',\n",
       " 'k',\n",
       " '孩',\n",
       " '오',\n",
       " '花',\n",
       " '今',\n",
       " '麗',\n",
       " 'Ｄ',\n",
       " 'Ｋ',\n",
       " '案',\n",
       " '览',\n",
       " '族',\n",
       " '岬',\n",
       " '弐',\n",
       " '巨',\n",
       " '芳',\n",
       " 'Ү',\n",
       " '섬',\n",
       " '토',\n",
       " '紀',\n",
       " '返',\n",
       " '직',\n",
       " '百',\n",
       " '厲',\n",
       " '辽',\n",
       " 'ኢ',\n",
       " '勃',\n",
       " 'Ḥ',\n",
       " '可',\n",
       " 'ノ',\n",
       " '판',\n",
       " '터',\n",
       " '套',\n",
       " '학',\n",
       " 'आ',\n",
       " '倮',\n",
       " '埼',\n",
       " 'ろ',\n",
       " 'Ś',\n",
       " '牙',\n",
       " 'ه',\n",
       " '静',\n",
       " '異',\n",
       " '青',\n",
       " '일',\n",
       " 'ך',\n",
       " '２',\n",
       " '综',\n",
       " '沟',\n",
       " 'Ļ',\n",
       " '술',\n",
       " 'ム',\n",
       " '宝',\n",
       " '儒',\n",
       " '熙',\n",
       " ',',\n",
       " '轟',\n",
       " '猓',\n",
       " 'Ｓ',\n",
       " '國',\n",
       " '3',\n",
       " 'ә',\n",
       " '磁',\n",
       " 'Լ',\n",
       " '博',\n",
       " '페',\n",
       " 'ᕿ',\n",
       " 'Й',\n",
       " '有',\n",
       " '梅',\n",
       " 'I',\n",
       " '貞',\n",
       " '혼',\n",
       " '팅',\n",
       " '鍾',\n",
       " '味',\n",
       " 'С',\n",
       " 'B',\n",
       " 'ᠮ',\n",
       " 'σ',\n",
       " '接',\n",
       " 'چ',\n",
       " 'る',\n",
       " '血',\n",
       " '怜',\n",
       " '茜',\n",
       " '茶',\n",
       " 'ᕐ',\n",
       " 'セ',\n",
       " '皇',\n",
       " '并',\n",
       " '俗',\n",
       " 'け',\n",
       " '한',\n",
       " '挺',\n",
       " '賛',\n",
       " '房',\n",
       " '渡',\n",
       " '錢',\n",
       " '舰',\n",
       " '工',\n",
       " '主',\n",
       " '浦',\n",
       " '봉',\n",
       " '盛',\n",
       " 'Ŷ',\n",
       " 'F',\n",
       " '铨',\n",
       " '咄',\n",
       " 'ᾶ',\n",
       " 'ї',\n",
       " '輝',\n",
       " '演',\n",
       " '갑',\n",
       " 'か',\n",
       " '러',\n",
       " '금',\n",
       " '백',\n",
       " '제',\n",
       " 'ᛃ',\n",
       " '姜',\n",
       " '#',\n",
       " '서',\n",
       " '빅',\n",
       " 'へ',\n",
       " 'ꀒ',\n",
       " '批',\n",
       " '포',\n",
       " '冲',\n",
       " 'ギ',\n",
       " '1',\n",
       " '출',\n",
       " '欢',\n",
       " '蔵',\n",
       " '億',\n",
       " '羽',\n",
       " '旋',\n",
       " 'Ｑ',\n",
       " '余',\n",
       " '出',\n",
       " '鼠',\n",
       " 'ψ',\n",
       " 'ナ',\n",
       " '鸣',\n",
       " '盤',\n",
       " '양',\n",
       " '傳',\n",
       " '씨',\n",
       " '순',\n",
       " '裕',\n",
       " '萬',\n",
       " 'デ',\n",
       " '梁',\n",
       " 'ק',\n",
       " 'न',\n",
       " '希',\n",
       " '伞',\n",
       " '좋',\n",
       " 'Ḵ',\n",
       " '亮',\n",
       " '温',\n",
       " '잘',\n",
       " 'ソ',\n",
       " '—',\n",
       " 'n',\n",
       " '伏',\n",
       " 'ｈ',\n",
       " '飞',\n",
       " '블',\n",
       " '합',\n",
       " 'พ',\n",
       " 'ن',\n",
       " 'Z',\n",
       " '阪',\n",
       " '度',\n",
       " '评',\n",
       " '김',\n",
       " '른',\n",
       " 'ტ',\n",
       " '달',\n",
       " '书',\n",
       " 'ɒ',\n",
       " '佛',\n",
       " '箱',\n",
       " '潤',\n",
       " '열',\n",
       " '廻',\n",
       " '鹏',\n",
       " 'ˁ',\n",
       " '居',\n",
       " '千',\n",
       " '麩',\n",
       " '馆',\n",
       " '帶',\n",
       " '祐',\n",
       " '走',\n",
       " '旅',\n",
       " '筑',\n",
       " '按',\n",
       " '嵩',\n",
       " 'W',\n",
       " 'қ',\n",
       " 'E',\n",
       " '巢',\n",
       " '강',\n",
       " 'f',\n",
       " '清',\n",
       " '麺',\n",
       " '９',\n",
       " 'レ',\n",
       " '청',\n",
       " 'ז',\n",
       " '신',\n",
       " '분',\n",
       " '버',\n",
       " '服',\n",
       " '정',\n",
       " '次',\n",
       " 'ᖅ',\n",
       " '誌',\n",
       " '殷',\n",
       " '조',\n",
       " '虚',\n",
       " '壬',\n",
       " '條',\n",
       " '説',\n",
       " '树',\n",
       " 'ね',\n",
       " '약',\n",
       " 'ス',\n",
       " '放',\n",
       " '看',\n",
       " 'դ',\n",
       " 'ќ',\n",
       " '코',\n",
       " '茅',\n",
       " '訊',\n",
       " '通',\n",
       " '5',\n",
       " '饅',\n",
       " '孙',\n",
       " '拍',\n",
       " '伍',\n",
       " 'ʼ',\n",
       " '칼',\n",
       " '항',\n",
       " '片',\n",
       " '蔣',\n",
       " 'g',\n",
       " '込',\n",
       " 'ล',\n",
       " '료',\n",
       " '池',\n",
       " '元',\n",
       " '대',\n",
       " '笔',\n",
       " '士',\n",
       " '顾',\n",
       " '栄',\n",
       " '懷',\n",
       " '자',\n",
       " '丹',\n",
       " '辑',\n",
       " '豹',\n",
       " '獎',\n",
       " '蕭',\n",
       " '福',\n",
       " '臨',\n",
       " '狱',\n",
       " '紺',\n",
       " '걸',\n",
       " '콤',\n",
       " '亞',\n",
       " 'ת',\n",
       " '암',\n",
       " 'љ',\n",
       " '下',\n",
       " '鄙',\n",
       " '試',\n",
       " '状',\n",
       " '涙',\n",
       " '법',\n",
       " 'Ď',\n",
       " 'Μ',\n",
       " '밤',\n",
       " 'Մ',\n",
       " 'b',\n",
       " '识',\n",
       " '底',\n",
       " 'ἀ',\n",
       " '搞',\n",
       " '帺',\n",
       " '毓',\n",
       " '格',\n",
       " '龙',\n",
       " '탄',\n",
       " '廉',\n",
       " 'ง',\n",
       " '純',\n",
       " 'ἰ',\n",
       " '錯',\n",
       " '协',\n",
       " 'ǚ',\n",
       " 'り',\n",
       " '만',\n",
       " '宋',\n",
       " '铁',\n",
       " '县',\n",
       " '즌',\n",
       " '卨',\n",
       " 'ች',\n",
       " '重',\n",
       " '臣',\n",
       " '院',\n",
       " 'づ',\n",
       " '닛',\n",
       " '姐',\n",
       " '封',\n",
       " 'つ',\n",
       " '咬',\n",
       " '製',\n",
       " '駛',\n",
       " 'Ἡ',\n",
       " '堂',\n",
       " '蔡',\n",
       " '松',\n",
       " '蓝',\n",
       " '覺',\n",
       " '坊',\n",
       " '降',\n",
       " '庄',\n",
       " 'վ',\n",
       " '３',\n",
       " '楷',\n",
       " '齒',\n",
       " '闻',\n",
       " '偏',\n",
       " '级',\n",
       " 'Π',\n",
       " '韩',\n",
       " '住',\n",
       " 'よ',\n",
       " '称',\n",
       " '철',\n",
       " '固',\n",
       " '師',\n",
       " '動',\n",
       " 'ה',\n",
       " 'ὺ',\n",
       " 'そ',\n",
       " 'Р',\n",
       " 'ջ',\n",
       " '来',\n",
       " 'Դ',\n",
       " 'ᠲ',\n",
       " 'ճ',\n",
       " 'Ν',\n",
       " '위',\n",
       " '瑜',\n",
       " '록',\n",
       " '確',\n",
       " '杰',\n",
       " '郷',\n",
       " '界',\n",
       " '尖',\n",
       " '助',\n",
       " '케',\n",
       " 'T',\n",
       " '沢',\n",
       " 'ስ',\n",
       " 'じ',\n",
       " '眼',\n",
       " '노',\n",
       " '虞',\n",
       " '축',\n",
       " 'и',\n",
       " '队',\n",
       " '麭',\n",
       " '研',\n",
       " '庫',\n",
       " '弾',\n",
       " 'τ',\n",
       " 'ゲ',\n",
       " '澎',\n",
       " 'Y',\n",
       " 'ი',\n",
       " 'ι',\n",
       " '易',\n",
       " '騰',\n",
       " '平',\n",
       " '秘',\n",
       " '네',\n",
       " '抄',\n",
       " '盼',\n",
       " '呼',\n",
       " '鯑',\n",
       " '뉴',\n",
       " '襲',\n",
       " '祁',\n",
       " '和',\n",
       " '엘',\n",
       " '鯖',\n",
       " '翼',\n",
       " '位',\n",
       " 'Ш',\n",
       " '森',\n",
       " '幕',\n",
       " '役',\n",
       " '군',\n",
       " 'פ',\n",
       " '與',\n",
       " '狼',\n",
       " '용',\n",
       " '水',\n",
       " '坛',\n",
       " '戲',\n",
       " '勁',\n",
       " '加',\n",
       " 'υ',\n",
       " '何',\n",
       " '罗',\n",
       " '호',\n",
       " '当',\n",
       " '山',\n",
       " '濟',\n",
       " '豆',\n",
       " '浅',\n",
       " '组',\n",
       " 'ὄ',\n",
       " 'ት',\n",
       " '身',\n",
       " '炒',\n",
       " '隈',\n",
       " '데',\n",
       " '雅',\n",
       " '対',\n",
       " '>',\n",
       " '益',\n",
       " '广',\n",
       " 'ळ',\n",
       " 'Ё',\n",
       " '留',\n",
       " '斬',\n",
       " '庭',\n",
       " '때',\n",
       " '嵐',\n",
       " 'a',\n",
       " 'ν',\n",
       " 'Т',\n",
       " '眞',\n",
       " '局',\n",
       " '限',\n",
       " '課',\n",
       " '憐',\n",
       " 'შ',\n",
       " '录',\n",
       " 'آ',\n",
       " '晓',\n",
       " '財',\n",
       " '上',\n",
       " '攀',\n",
       " 'م',\n",
       " '응',\n",
       " '營',\n",
       " '灯',\n",
       " '왕',\n",
       " '역',\n",
       " 'ῇ',\n",
       " 'ử',\n",
       " '纵',\n",
       " '脈',\n",
       " 'Ī',\n",
       " '廣',\n",
       " '碧',\n",
       " '槻',\n",
       " '표',\n",
       " '편',\n",
       " '禮',\n",
       " '世',\n",
       " '儀',\n",
       " '澤',\n",
       " '赵',\n",
       " 'إ',\n",
       " '석',\n",
       " '薇',\n",
       " '睡',\n",
       " 'ד',\n",
       " '券',\n",
       " 'ὀ',\n",
       " '头',\n",
       " '胥',\n",
       " '师',\n",
       " '鳳',\n",
       " '０',\n",
       " '目',\n",
       " 'Я',\n",
       " '烟',\n",
       " '绘',\n",
       " '妲',\n",
       " '故',\n",
       " 'µ',\n",
       " 'η',\n",
       " '果',\n",
       " '压',\n",
       " '타',\n",
       " '彙',\n",
       " '性',\n",
       " '棟',\n",
       " '7',\n",
       " '롱',\n",
       " '显',\n",
       " '간',\n",
       " '범',\n",
       " 'ỗ',\n",
       " '噌',\n",
       " '-',\n",
       " '두',\n",
       " '媽',\n",
       " 'ῳ',\n",
       " '邠',\n",
       " '负',\n",
       " '戚',\n",
       " 'ㅏ',\n",
       " '利',\n",
       " '桜',\n",
       " '協',\n",
       " '孫',\n",
       " 'ʃ',\n",
       " '昆',\n",
       " '怖',\n",
       " '亡',\n",
       " 'チ',\n",
       " '焉',\n",
       " '橋',\n",
       " 'ส',\n",
       " '縄',\n",
       " 'ほ',\n",
       " '特',\n",
       " 'ʔ',\n",
       " '板',\n",
       " 'Г',\n",
       " 'Ъ',\n",
       " 'Ʌ',\n",
       " 'ድ',\n",
       " '최',\n",
       " '李',\n",
       " '合',\n",
       " '冠',\n",
       " '克',\n",
       " '디',\n",
       " '羊',\n",
       " '袁',\n",
       " 'テ',\n",
       " 'า',\n",
       " '茲',\n",
       " '¾',\n",
       " 'ถ',\n",
       " '渣',\n",
       " '闫',\n",
       " '餅',\n",
       " 'Ｂ',\n",
       " '별',\n",
       " '考',\n",
       " 'თ',\n",
       " '壁',\n",
       " '選',\n",
       " '退',\n",
       " 'օ',\n",
       " 'Ķ',\n",
       " 'ظ',\n",
       " '졌',\n",
       " 'ᠠ',\n",
       " '파',\n",
       " '鴻',\n",
       " '名',\n",
       " '빙',\n",
       " '殺',\n",
       " '恐',\n",
       " '猴',\n",
       " '提',\n",
       " '伐',\n",
       " '빵',\n",
       " 'կ',\n",
       " '색',\n",
       " 'ド',\n",
       " 'ề',\n",
       " '腾',\n",
       " '章',\n",
       " '玢',\n",
       " '夜',\n",
       " '보',\n",
       " 'ы',\n",
       " 'Ż',\n",
       " 'で',\n",
       " '黒',\n",
       " '併',\n",
       " '术',\n",
       " '市',\n",
       " '林',\n",
       " '톨',\n",
       " '护',\n",
       " 'ቶ',\n",
       " 'ấ',\n",
       " 'ნ',\n",
       " '带',\n",
       " '先',\n",
       " '範',\n",
       " '碟',\n",
       " '武',\n",
       " '실',\n",
       " '伝',\n",
       " 'Խ',\n",
       " '기',\n",
       " '손',\n",
       " '试',\n",
       " '트',\n",
       " '와',\n",
       " '됐',\n",
       " 'አ',\n",
       " '雑',\n",
       " 'é',\n",
       " '他',\n",
       " '伦',\n",
       " 'ك',\n",
       " '數',\n",
       " '赛',\n",
       " '볼',\n",
       " '记',\n",
       " 'ㆍ',\n",
       " '소',\n",
       " 'ぎ',\n",
       " '발',\n",
       " 'ª',\n",
       " '東',\n",
       " 'ω',\n",
       " '(',\n",
       " '뿐',\n",
       " '鄭',\n",
       " '虬',\n",
       " '擔',\n",
       " '耀',\n",
       " '識',\n",
       " 'Ἴ',\n",
       " '碉',\n",
       " '恋',\n",
       " 'ላ',\n",
       " '경',\n",
       " '亨',\n",
       " '未',\n",
       " '写',\n",
       " 'Ə',\n",
       " '翰',\n",
       " '衛',\n",
       " 'ር',\n",
       " '屄',\n",
       " 'ャ',\n",
       " '险',\n",
       " 'Б',\n",
       " '笺',\n",
       " '里',\n",
       " '单',\n",
       " 'p',\n",
       " 'ራ',\n",
       " '琵',\n",
       " 'め',\n",
       " '싶',\n",
       " 'պ',\n",
       " 'ぽ',\n",
       " '賦',\n",
       " 'q',\n",
       " '序',\n",
       " '霊',\n",
       " '狸',\n",
       " 'پ',\n",
       " '曾',\n",
       " '月',\n",
       " '撃',\n",
       " '智',\n",
       " 'แ',\n",
       " '色',\n",
       " 'Ｊ',\n",
       " '偶',\n",
       " '협',\n",
       " 'く',\n",
       " 'ㅓ',\n",
       " 'ᚱ',\n",
       " 'ლ',\n",
       " '円',\n",
       " '垣',\n",
       " '弟',\n",
       " '에',\n",
       " 'ɜ',\n",
       " 'だ',\n",
       " ...]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3080\n"
     ]
    }
   ],
   "source": [
    "words=df_x.iloc[:,1]\n",
    "print (len(words))\n",
    "print( type(words))\n",
    "char_list=[]\n",
    "\n",
    "import unicodedata\n",
    "for word in words:\n",
    "        temp_list=list(word)\n",
    "        char_list += temp_list\n",
    "        \n",
    "char_list=list(set(char_list))\n",
    "display(char_list)\n",
    "print (len(char_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Vocabulary count and assigning each character a numeric value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3080\n"
     ]
    }
   ],
   "source": [
    "# VOCAB COUNT\n",
    "\n",
    "VOCAB=char_list\n",
    "VOCAB_SIZE= len(VOCAB)\n",
    "print (VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict={}\n",
    "length=len(char_list)\n",
    "for i in range (length):\n",
    "    mydict[char_list[i]]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict[' ']=length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_of_unique=len(char_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "hot_vec= np.zeros((VOCAB_SIZE,VOCAB_SIZE),int)\n",
    "np.fill_diagonal(hot_vec,1)\n",
    "hot_vec_dict={}\n",
    "\n",
    "index=0\n",
    "for word in VOCAB:\n",
    "    hot_vec_dict[word]=hot_vec[index].reshape(1,VOCAB_SIZE)\n",
    "    index+=1\n",
    "    \n",
    "#assign \"space\" a vec of zero\n",
    "hot_vec_dict[\" \"]=np.zeros((1,VOCAB_SIZE),int)\n",
    "print (len(hot_vec_dict))\n",
    "display(hot_vec_dict[\" \"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making One-Hot-Vectors for our classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484145\n",
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ADDRESS': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " 'CARDINAL': array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'DATE': array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'DECIMAL': array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'DIGIT': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " 'FRACTION': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " 'LETTERS': array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'MEASURE': array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'MONEY': array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " 'ORDINAL': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " 'PLAIN': array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'PUNCT': array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'TELEPHONE': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " 'TIME': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " 'VERBATIM': array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes_list=df_x.iloc[:,0]\n",
    "class_hot_vec\n",
    "ind=0\n",
    "class_hotvec_dict={}\n",
    "for clas in unique_classes:\n",
    "    class_hotvec_dict[clas]=class_hot_vec[ind]\n",
    "    ind+=1\n",
    "    \n",
    "\n",
    "print (len(classes_list))\n",
    "print (len(class_hotvec_dict))\n",
    "display(class_hotvec_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of YTRAIN:  484145\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YTRAIN=[]\n",
    "for clas in classes_list:\n",
    "    YTRAIN.append(class_hotvec_dict[clas])\n",
    "\n",
    "print (\"len of YTRAIN: \",len(YTRAIN))\n",
    "print (YTRAIN[10])\n",
    "YTRAIN[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words:  484145\n"
     ]
    }
   ],
   "source": [
    "#del df_x\n",
    "print(\"Total Words: \",len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Vectors out of each word from our test data and adding padding  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length=0\n",
    "final_dict={}\n",
    "final_word=[]\n",
    "for word in words:\n",
    "    length=len(word)\n",
    "    array=[]\n",
    "    if max_length<length:     \n",
    "        max_length=length\n",
    "    for i in range(length):\n",
    "        array.append(mydict[word[i]])\n",
    "    zeros=0\n",
    "    if max_word_len>length:\n",
    "        l=max_word_len-length\n",
    "        zeros=[]\n",
    "        for i in range(l):\n",
    "            zeros.append(length_of_unique)\n",
    "        #print (zeros)\n",
    "        zeros.extend(array)\n",
    "        final_word.append(zeros)\n",
    "    else:\n",
    "        final_word.append(array)\n",
    "    #print (zeros)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(484145, 323)\n"
     ]
    }
   ],
   "source": [
    "final_word=np.array(final_word)\n",
    "print (final_word.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print (\"Len of Ytrain:\", len(YTRAIN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing One-Hot-Vec's for Lables to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile=\"C:\\\\Users\\\\Dani-Desktop\\\\Desktop\\\\NLP DATA\\\\alldata\\\\y_train\"\n",
    "np.savez_compressed(outfile, YTRAIN=YTRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading lables vectors from file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['YTRAIN']\n",
      "Files Read\n"
     ]
    }
   ],
   "source": [
    "outfile2=\"C:\\\\Users\\\\Dani-Desktop\\\\Desktop\\\\NLP DATA\\\\alldata\\\\y_train.npz\"\n",
    "npzfile = np.load(outfile2)\n",
    "print (npzfile.files)\n",
    "#x_train=npzfile['XTRAIN']\n",
    "x_train_f=final_word\n",
    "y_train_f=npzfile['YTRAIN']\n",
    "npzfile.close()\n",
    "print(\"Files Read\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(484145, 323)\n",
      "(484145, 15)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_f.shape)\n",
    "print(y_train_f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df\n",
    "del df_c\n",
    "del df_x\n",
    "del YTRAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an LSTM model in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(13)\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, GRU\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting the data into Test and Training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(387316, 323)\n",
      "(387316, 15)\n",
      "(96827, 323)\n",
      "(96827, 15)\n"
     ]
    }
   ],
   "source": [
    "max_features = lenx\n",
    "x_train=x_train_f[:387316]\n",
    "y_train=y_train_f[:387316]\n",
    "x_test=x_train_f[387317:-1]\n",
    "y_test=y_train_f[387317:-1]\n",
    "maxlen = max_word_len\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an LSTM model with Softmax activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 323, 10)           30810     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 323, 20)           2480      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 15)                315       \n",
      "=================================================================\n",
      "Total params: 36,885\n",
      "Trainable params: 36,885\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=VOCAB_SIZE+1, output_dim=10, input_length=max_word_len))\n",
    "model.add(LSTM(20, return_sequences=True))\n",
    "model.add(LSTM(20, return_sequences=False))\n",
    "model.add(Dense(15, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "filepath=\"C:\\\\Users\\\\Dani-Desktop\\\\Desktop\\\\NLP DATA\\\\alldata\\\\weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 387316 samples, validate on 96827 samples\n",
      "Epoch 1/10\n",
      "387264/387316 [============================>.] - ETA: 0s - loss: 0.2250 - acc: 0.9324Epoch 00000: val_loss improved from inf to 0.12005, saving model to C:\\Users\\Dani-Desktop\\Desktop\\NLP DATA\\alldata\\weights-improvement-00-0.2250.hdf5\n",
      "387316/387316 [==============================] - 2196s - loss: 0.2250 - acc: 0.9324 - val_loss: 0.1201 - val_acc: 0.9565\n",
      "Epoch 2/10\n",
      " 55744/387316 [===>..........................] - ETA: 1745s - loss: 0.1178 - acc: 0.9610"
     ]
    }
   ],
   "source": [
    "res=model.fit(x_train,y_train,batch_size=64,validation_data=(x_test,y_test),callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying Loss and Accuracy graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(epochs)\n",
    "plt.plot(x, res.history['acc'], label='LSTM train')\n",
    "plt.plot(x, res.history['val_acc'], label='LSTM val')\n",
    "\n",
    "plt.title('Accuracy')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, res.history['loss'], label='LSTM train')\n",
    "plt.plot(x, res.history['val_loss'], label='LSTM val')\n",
    "plt.title('Loss')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
